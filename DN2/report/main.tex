\documentclass[11pt]{article}
\input{preamble.tex}

\begin{document}
\maketitle

The entire code can be found on the \href{https://github.com/Edelwy/approximation-algorithms}{\textbf{GitHub repositroy}}. The below mentioned results analyzed and raw can also be found in the repository as well.

\section{Implementation of the Algorithms}

I chose to implement the algorithms in \cpp because it provides sufficient built-in functionality and flexibility, while remaining faster than many other languages. Firstly, here is the implementation of the algorithm used for \textbf{dynamic programming}. The \texttt{memo} table is used for memoization and is initialized to $0$ for every element.

\begin{minted}[fontsize=\fontsize{10.5pt}{11pt}, 
               bgcolor=gray!10, 
               breaklines=true]{cpp}

  bool CSolver::solveDYN( int n, int k, const std::vector<int>& numbers )
  {
      std::vector<std::vector<int>> memo( n, std::vector<int>( k, 0 ) );
      std::function<int( int, int )> solver = [&]( int i, int j ) -> int {
          if( i < 0 || j < 0 || i > n || j > k )
              return std::numeric_limits<int>::min();
  
          if( i == 0 || j == 0 )
              return 0;
  
          auto& mem = memo.at( i - 1 ).at( j - 1 );
          if( mem > 0 ) 
              return mem;
  
          const auto& num = numbers.at( i - 1 );
          mem = std::max( solver( i - 1, j ), solver( i - 1, j - num ) + num );
          return mem;
      };
      auto solution = solver( n, k );
      std::cout << fmt::format( "Solution found was {}.\n", solution );
      return solution == k;
  }
\end{minted}

Next algorithm is the \textbf{exhaustive search}. We do not actually add lists together but keep all elements in one set, which in \cpp is sorted by default. One minor improvement from the base algorithm was adding a \textbf{break} sentance if the solution is found.

\begin{minted}[fontsize=\fontsize{10.5pt}{11pt}, 
    bgcolor=gray!10, 
    breaklines=true]{cpp}

  bool CSolver::solveEXH( int n, int k, const std::vector<int>& numbers )
  {
      std::set<int> sums = { 0 };
      for ( int i = 1; i < n; i++ ) {
          auto currSums = sums;
  
          for ( const auto element : currSums ) {
              auto newElement = element + numbers.at( i );
              if ( newElement <= k )
                  sums.insert( newElement );
              if ( newElement == k)
                  break;
          }
      }
      auto solution = *sums.rbegin();
      std::cout << fmt::format( "Maximal element in set is {}.\n", solution );
      return solution == k;
  } 
\end{minted}

\pagebreak
The implementation of the \textbf{greedy algorithm} is optimized by sorting the numbers array first. If we frame this as a maximization problem, we are searching for the maximum sum not exceding $k$. Then this is a $0.5$-approximation, meaning the approximation is at least half as good as the actual solution.

\begin{minted}[fontsize=\fontsize{10.5pt}{11pt}, 
    bgcolor=gray!10, 
    breaklines=true]{cpp}

  bool CSolver::solveGRDY( int n, int k, const std::vector<int>& numbers )
  {
      auto sortedNumbers = numbers;
      std::sort( sortedNumbers.begin(), sortedNumbers.end() );
  
      int solution = 0;
      for ( int i = 0; i < n; i++ ) {
          const auto& element = sortedNumbers.at( i );
          if ( k - solution >= element )
              solution += element;
      }
      auto approx = fmt::format( "Approximation for {} is {}.\n", k, solution );
      approx += fmt::format( "Difference is {}.\n", k - solution );
      std::cout << approx;
      return solution == k;
  }  
\end{minted}

Finally, we have the \textbf{FPTAS algorithm} which is very similar to the exahustive search with addition of trimming the set based on the $\epsilon$ parameter. The iteration is stopped if the solution is found.

\begin{minted}[fontsize=\fontsize{10.5pt}{11pt}, 
    bgcolor=gray!10, 
    breaklines=true]{cpp}

  bool CSolver::solveFPTAS( int n, int k, const std::vector<int>& numbers )
  {
      auto delta = mEpsilon / ( 2 * n );
      std::set<int> sums = { 0 };
      for ( int i = 1; i < n; i++ ) {
          auto tmpSums = sums;
  
          for ( const auto element : tmpSums ) 
              sums.insert( element + numbers.at( i ) );
  
          auto last = *sums.begin();
          tmpSums = { last };
          for ( auto& element : sums ) {
              if( element <= k && element > last * ( 1 + delta ) ) {
                  tmpSums.insert( element );
                  last = element;
              }
              if ( element == k)
                  break;
          }
          sums = tmpSums;
      }
  
      auto solution = *sums.rbegin();
      auto approx = fmt::format( "Approximation for {} is {}. \n", k, solution );
      approx += fmt::format( "The epsilon value was {}.", mEpsilon );
      approx += fmt::format( "Difference is {}.\n", k - solution );
      std::cout << approx;
      return solution == k;
  }  
\end{minted}

Which algorithm is used is parsed from parameters and decided based on the enum value.

\begin{minted}[fontsize=\fontsize{10.5pt}{11pt}, 
    bgcolor=gray!10, 
    breaklines=true]{cpp}
  enum class EMode { DYN = 1, EXH = 2, GRDY = 3, FPTAS = 4 };
\end{minted}

\pagebreak

\section{Testing on Public Test Cases}

Firstly let us examine the performance of all four algorithms for the public test cases provided in \href{https://ucilnica.fri.uni-lj.si/mod/assign/view.php?id=32883}{spletna uÄilnica}. I implemented a \texttt{Benchmark} class available in the repository that times the performance. The $\epsilon$ value was $0.2$ for the fourth algorithm. There exists a \textbf{feasable folution} for every test case. 

\begin{figure}[!hbpt]
    \begin{minipage}{0.64\textwidth}
        \begin{table}[H]
            \centering
            \begin{tabular}{|l|c|c|c|c|} \hline
                \cellcolor{blue!20} & \multicolumn{4}{c|}{\cellcolor{blue!20}\texttt{time}} \\ \cline{2-5}
                \cellcolor{blue!20} \texttt{test} & \texttt{DYN} & \texttt{EXH} & \texttt{GRDY} & \texttt{FPTAS} \\ \hline
                \makecell[l]{ \texttt{n = 100} \\ \texttt{k = 200}} & 0.00003 & 0.00362 & 0.00001 & \cellcolor{red!20}{0.00895} \\ \hline
                \makecell[l]{ \texttt{n = 50} \\ \texttt{k = 200000}} & 0.00992 & \cellcolor{red!20}{1.14751} & 0.00001 & 0.02338 \\ \hline
                \makecell[l]{ \texttt{n = 500} \\ \texttt{k = 2000}} & 0.00020 & 0.25861 & 0.00006 & \cellcolor{red!20}{0.60971} \\ \hline
                \makecell[l]{ \texttt{n = 40} \\ \texttt{k = 1230000}} & 0.04424 & \cellcolor{red!20}{7.79745} & 0.00001 & 0.01751 \\ \hline
                \makecell[l]{ \texttt{n = 1000} \\ \texttt{k = 72000}} & 0.06364 & \cellcolor{red!20}{25.26750} & 0.00013 & 21.36842 \\ \hline
            \end{tabular}
            \caption{Time in seconds for the public test cases.}
        \end{table}
    \end{minipage}
    \begin{minipage}{0.35\textwidth}
        \begin{table}[H]
            \centering
            \begin{tabular}{|l|c|c|} \hline
                \cellcolor{blue!20} & \multicolumn{2}{c|}{\cellcolor{blue!20}\texttt{difference}} \\ \cline{2-3}
                \cellcolor{blue!20} \texttt{test} & \texttt{GRDY} & \texttt{FPTAS} \\ \hline
                \makecell[l]{ \texttt{n = 100} \\ \texttt{k = 200}}  & \cellcolor{red!20}{4} & 0 \\ \hline
                \makecell[l]{ \texttt{n = 50} \\ \texttt{k = 200000}} &  \cellcolor{red!20}{19516} & 337 \\ \hline
                \makecell[l]{ \texttt{n = 500} \\ \texttt{k = 2000}} &  \cellcolor{red!20}{34} & 0 \\ \hline
                \makecell[l]{ \texttt{n = 40} \\ \texttt{k = 1230000}} &  \cellcolor{red!20}{33687} & 4 \\ \hline
                \makecell[l]{ \texttt{n = 1000} \\ \texttt{k = 72000}} & \cellcolor{red!20}{897} & 7 \\ \hline
            \end{tabular}
            \caption{Difference from $k$.}
        \end{table} 
    \end{minipage}  
\end{figure}

The red cells represent the longest running time. The first case was easily solveble by all algorithms with time being \textbf{under a second}. The \textbf{dynamic programming} approach performed drastically better than the \textbf{exhaustive search} in terms of finding an optimal solution. It even performed better than the \textbf{FPTAS} algorithm in most cases. While the greedy algorithm performed better timewise, it did perform a lot worse in terms of approximation.

\section{Test Case Generation for Hard Scenarios}

Let us concentrate on challenging examples for each algorithm we implemented. To ensure better comparability, we will fix $n$ to $500$. One particularly hard case for dynamic programming arises when the input list consists entirely of very small values, such as \textbf{all ones}. In this situation, the algorithm makes only minimal progress in both the index and sum dimensions. As a result, the algorithm is forced to explore almost the entire $n \times k$ table.

Another difficult example for dynamic programming arises when determining that no solution exists in a very large $n \times k$ table, even in trivial cases. Suppose we choose a relatively large $k$ and a list of numbers whose \textbf{total sum is less than} $k$, making it impossible to reach the target. In such cases, the algorithm still allocates the full table and explores many combinations before ultimately concluding that no solution exists. 

Both cases mentioned above are difficult for the \textbf{exahustive search} as well as there rarely any filtering and the list becomes very large. Since we are working with set that should not be an issue. We can modify the second case in a way that every sum of arbitrary elements from the list is unique. We can achieve this by taking powers of $2$ as the initial list, effectively mimicking binary representation.

\end{document}